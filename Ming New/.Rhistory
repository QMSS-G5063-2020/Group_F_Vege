install.packages("worldcloud")
install.packages("wordcloud")
library(wordcloud)
sotu_tf_idf <- sotu_td %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf_idf))
sotu_tf_idf
wordcloud(term_frequency_DT$term, term_frequency_DT$tf,
max.words = 100, colors = "red")
wordcloud(sotu_tf_idf,
max.words = 100, colors = "red")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf
max.words = 100, colors = "red")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 100, colors = "red")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 10, colors = "red")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 20, colors = "red")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 30, colors = "red")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 30, colors = "black")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 30, colors = "yellow")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 30, colors = "orange")
View(un1000)
View(un1000)
View(kic)
View(kic)
Data1=data.frame(su1000$top_category,su1000$blurb)
head(Data1)
docs <- data.frame(doc_id = 1:1000,
text = su1000$blurb,stringsAsFactors = FALSE)
docs$text=str_trim(gsub("[A-Z]{2,}","",docs$text))
df_source <- DataframeSource(docs)
df_corpus <- VCorpus(df_source)
df_corpus
docs <- data.frame(doc_id = 1:1000,
text = su1000$blurb,stringsAsFactors = FALSE)
docs$text=str_trim(gsub("[A-Z]{2,}","",docs$text))
df_source <- DataframeSource(docs)
df_corpus <- VCorpus(df_source)
df_corpus
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
# We could add more stop words as above
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
s_clean <- clean_corpus(df_corpus)
stemCompletion2 <- function(x, dictionary) {
x <- unlist(strsplit(as.character(x), " "))
# # Oddly, stemCompletion completes an empty string to
# a word in dictionary. Remove empty string to avoid issue.
x <- x[x != ""]
x <- stemDocument(x)
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
clean1 <- as.VCorpus(clean_stemmed)
sotu_tdm <- DocumentTermMatrix(clean1)
sotu_tdm
sotu_m <- as.matrix(sotu_tdm)
dim(sotu_m)
sotu_td <- tidy(sotu_tdm)
head(sotu_td)
sotu_tf_idf <- sotu_td %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf_idf))
sotu_tf_idf
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 30, colors = "orange")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 10, colors = "orange")
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 20, colors = "orange")
clean1 <- as.VCorpus(clean_stemmed)
sotu_tdm <- DocumentTermMatrix(clean1)
sotu_tdm
sotu_m <- as.matrix(sotu_tdm)
dim(sotu_m)
sotu_td <- tidy(sotu_tdm)
head(sotu_td)
sotu_tf_DT <- sotu_td %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf_idf))
sotu_tf_DT
wordcloud(sotu_tf_idf$term,sotu_tf_idf$tf,
max.words = 20, colors = "orange")
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
type(sotu_tf_DT)
class(sotu_tf_DT)
install.packages("RColorBrewer")
library(RColorBrewer)
library(wordcloud2)
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
library(leaflet)
library(knitr) # I think this is the key.
library(leaflet) # also, it's probably a better idea to load librarys before use them
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(RANN)
library(ggplot2)
library(lubridate)
library(ggmap)
library(sf)
library(geojsonio)
library(ggthemes)
library(viridis)
library(raster)
library(urbnmapr)
library(tidyverse)
library(stringr)
library(tm)
library(SnowballC)
library(tidytext)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
kic=read.csv("/Users/minggong/Documents/GitHub/course_materials/Exercises/09_kickstarter/kickstarter_projects_2020_02.csv")
head(kic)
levels(kic$state)
kic$state=as.character(kic$state)
kic1=kic
kic1$state[which(kic1$state!="successful")]=0
kic1$state[which(kic1$state=="successful")]=1
kic1$state=as.numeric(kic1$state)
m=aggregate(kic1$state, by=list(kic1$top_category), FUN=sum)
m
names(m)
names(m)<-c("Var1","x")
m
table(kic$top_category)
w=table(kic$top_category)
w=as.data.frame(w)
total <- merge(m,w,by="Var1")
y=total$x/total$Freq
total$y=y
total
total %>%
mutate(Var1=fct_reorder(Var1,y))%>%
ggplot(aes(x=Var1, y=y,fill=as.factor(y))) +
geom_bar(stat = "identity",fill="#f68060", alpha=.6, width=.4) +
coord_flip() +
xlab("") +
theme_bw()
su1000<-kic1[order(-kic1$pledged),]
su1000=su1000[1:1000,]
su1000
un1000<-kic1[order(kic1$pledged),]
un1000=un1000[1:1000,]
un1000
Data1=data.frame(su1000$top_category,su1000$blurb)
head(Data1)
docs <- data.frame(doc_id = 1:1000,
text = su1000$blurb,stringsAsFactors = FALSE)
docs$text=str_trim(gsub("[A-Z]{2,}","",docs$text))
df_source <- DataframeSource(docs)
df_corpus <- VCorpus(df_source)
df_corpus
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
# We could add more stop words as above
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
s_clean <- clean_corpus(df_corpus)
stemCompletion2 <- function(x, dictionary) {
x <- unlist(strsplit(as.character(x), " "))
# # Oddly, stemCompletion completes an empty string to
# a word in dictionary. Remove empty string to avoid issue.
x <- x[x != ""]
x <- stemDocument(x)
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
clean_stemmed<- lapply( s_clean, stemCompletion2,
dictionary=s_clean)
clean_stemmed[[1]]$content
clean1 <- as.VCorpus(clean_stemmed)
sotu_tdm <- DocumentTermMatrix(clean1)
sotu_tdm
sotu_m <- as.matrix(sotu_tdm)
dim(sotu_m)
sotu_td <- tidy(sotu_tdm)
head(sotu_td)
sotu_tf_DT <- sotu_td %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf_idf))
sotu_tf_DT
class(sotu_tf_DT)
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
aggregate(term_frequency_DT,term_frequency_DTterm_frequency_DT$term,sum)
aggregate(term_frequency_DT,term_frequency_DTterm_frequency_DT$term,sum)
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
aggregate(sotu_tf_DT,sotu_tf_DT$term,sum)
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
aggregate(sotu_tf_DT$term,sotu_tf_DT$tf,sum)
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
aggregate(sotu_tf_DT,sotu_tf_DT$term,sum)
View(sotu_tf_DT)
View(sotu_tf_DT)
View(sotu_tf_DT)
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
aggregate(sotu_tf_DT$tf,sotu_tf_DT[,2],sum)
a=aggregate(sotu_tf_DT$tf,sotu_tf_DT[,2],sum)
wordcloud(sotu_tf_DT$term,sotu_tf_DT$tf,
max.words = 20, colors = "orange")
a=aggregate(sotu_tf_DT$tf,sotu_tf_DT[,2],sum)
wordcloud(a$term,a$x,
max.words = 20, colors = "orange")
a=aggregate(sotu_tf_DT$tf,sotu_tf_DT[,2],sum)
wordcloud(a$term,a$x,
max.words = 40, colors = "orange")
a=aggregate(sotu_tf_DT$tf,sotu_tf_DT[,2],sum)
wordcloud(a$term,a$x,
min.freq = 1,max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
a=aggregate(sotu_tf_DT$tf,sotu_tf_DT[,2],sum)
wordcloud(a$term,a$x,
min.freq = 1,max.words=50, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
wordcloud2(data=a, size=1.6, color='random-dark')
wordcloud2(a$term,a$x, size=1.6, color='random-dark')
wordcloud2(data=a$term,data=a$x, size=1.6, color='random-dark')
wordcloud2(data=a$x, size=1.6, color='random-dark')
wordcloud2(data=a, size=1.6, color='random-dark')
wordcloud2(data=df <-a[order(a$x),], size=1.6, color='random-dark')
wordcloud2(data=df <-a[order(a$x),], size=1.6, color='random-dark')
wordcloud2(df <-a[order(a$x),], size=1.6, color='random-dark')
wordcloud2(a[order(a$x),], size=1.6, color='random-dark')
Data2=data.frame(un1000$top_category,un1000$blurb)
head(Data2)
docs1 <- data.frame(doc_id = 1:1000,
text = un1000$blurb,stringsAsFactors = FALSE)
docs1$text=str_trim(gsub("[A-Z]{2,}","",docs1$text))
df_source <- DataframeSource(docs1)
df_corpus <- VCorpus(df_source)
df_corpus
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
# We could add more stop words as above
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
s_clean <- clean_corpus(df_corpus)
stemCompletion2 <- function(x, dictionary) {
x <- unlist(strsplit(as.character(x), " "))
# # Oddly, stemCompletion completes an empty string to
# a word in dictionary. Remove empty string to avoid issue.
x <- x[x != ""]
x <- stemDocument(x)
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
clean_stemmed1<- lapply( s_clean1, stemCompletion2,
dictionary=s_clean1)
clean_stemmed1<- lapply( s_clean, stemCompletion2,
dictionary=s_clean)
clean_stemmed1[[1]]$content
clean2 <- as.VCorpus(clean_stemmed1)
sotu_tdm <- DocumentTermMatrix(clean2)
sotu_tdm
sotu_m <- as.matrix(sotu_tdm)
dim(sotu_m)
sotu_td <- tidy(sotu_tdm)
head(sotu_td)
sotu_tf_DT <- sotu_td %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf_idf))
sotu_tf_DT
b=aggregate(sotu_tf_DT$tf,sotu_tf_DT[,2],sum)
wordcloud(b$term,b$x,
min.freq = 1,max.words=50, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
a <-a[order(a$x),]
View(b)
View(b)
View(a)
View(a)
a <-a[order(a$x),]
b[which(b$term== a[1,1]),]
a <-a[order(a$x),]
b[which(b$term== a[2,1]),]
a <-a[order(a$x),]
b[which(b$term== a[3,1]),]
a <-a[order(a$x),]
b[which(b$term== a[3,1]),]
a <-a[order(-a$x),]
b[which(b$term== a[3,1]),]
a <-a[order(-a$x),]
b[which(b$term== a[1,1]),]
View(a)
View(a)
cy=data.frame(matrix(ncol = 2, nrow = 10)), c('term','freq'))
cy=data.frame(matrix(ncol = 2, nrow = 10)),c('term','freq'))
cy=setNames[data.frame(matrix(ncol = 2, nrow = 10))),c('term','freq')]
cy=setNames(data.frame(matrix(ncol = 2, nrow = 10)),c('term','freq'))
cy=setNames(data.frame(matrix(ncol = 2, nrow = 10)),c('term','freq'))
cy
View(cy)
View(cy)
total <- merge(a,b,by="term")
View(total)
View(total)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
View(total)
View(total)
library(plotrix)
install.packages("plotrix")
library(plotrix)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
p <- pyramid.plot(total$x.x, total$x.y,
labels = total$term,
gap = 10,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
p <- pyramid.plot(total$x.x, total$x.y,
labels = total$term,
gap = 10,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
p <- pyramid.plot(total$x.x, total$x.y,
labels = total$term,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = total$term,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = top10_total$term,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
top10_total=total[1:10,]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = top10_total$term,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
View(total)
View(total)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
total$x.x=total$x.x*10000
top10_total=total[1:10,]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = top10_total$term,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
total$x.x=total$x.x*10000
total$x.y=total$x.y*10000
top10_total=total[1:10,]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = top10_total$term,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
total$x.x=total$x.x*10000
total$x.y=total$x.y*10000
top10_total=total[1:10,]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = top10_total$term,
gap=5
top.labels = c("Successful", " ", "Unsuccess"),
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
total$x.x=total$x.x*10000
total$x.y=total$x.y*10000
top10_total=total[1:10,]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = top10_total$term,
gap=5,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
total$x.x=total$x.x*10000
total$x.y=total$x.y*10000
top10_total=total[1:10,]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = top10_total$term,
gap=10,
top.labels = c("Successful", " ", "Unsuccess"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
total <- merge(a,b,by="term")
total <-total[order(-total$x.x),]
total$x.x=total$x.x*10000
total$x.y=total$x.y*10000
top10_total=total[1:10,]
p <- pyramid.plot(top10_total$x.x, top10_total$x.y,
labels = top10_total$term,
gap=10,
top.labels = c("Successful", " ", "Unsuccessful"),
main = "Words in Common",
laxlab = NULL,
raxlab = NULL,
unit = NULL,
labelcex=0.5)
require(quanteda)
require(dplyr)
sotu_corpus <- corpus(sotu)  # convert to quanteda corpus
docs1 <- data.frame(doc_id = 1:1000,
text = un1000$blurb,stringsAsFactors = FALSE)
docs1$text=str_trim(gsub("[A-Z]{2,}","",docs1$text))
df_source <- DataframeSource(docs1)
df_corpus1 <- VCorpus(df_source)
df_corpus1
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
# We could add more stop words as above
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
s_clean <- clean_corpus(df_corpus1)
stemCompletion2 <- function(x, dictionary) {
x <- unlist(strsplit(as.character(x), " "))
# # Oddly, stemCompletion completes an empty string to
# a word in dictionary. Remove empty string to avoid issue.
x <- x[x != ""]
x <- stemDocument(x)
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
clean_stemmed1<- lapply( s_clean, stemCompletion2,
dictionary=s_clean)
clean_stemmed1[[1]]$content
require(quanteda)
require(dplyr)
# convert to quanteda corpus
FRE_sotu <- textstat_readability(df_corpus1,
measure=c('Flesch.Kincaid'))
